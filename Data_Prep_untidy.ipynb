{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first part is commented out because I dont want to accidentally start the pulling process all over again and waste bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# datasets = requests.get('https://api.census.gov/data.json')\n",
    "# jdata = datasets.json()\n",
    "# df = pd.DataFrame(jdata)\n",
    "# # df = pd.concat([df.drop('dataset', axis=1), df.dataset.apply(pd.Series)], axis=1)\n",
    "# df = df.dataset.apply(pd.Series)\n",
    "# df = df[~df.description.str.contains('phased out')]\n",
    "# df.loc[df['c_isTimeseries'] == True, 'c_vintage'] = df[df['c_isTimeseries'] == True].c_vintage.fillna('Time Series')\n",
    "# # vintages = df.c_vintage.value_counts().reset_index().values\n",
    "# df['code'] = df.identifier.str.split('/').apply(lambda x: x[-1]).astype(str)\n",
    "# df['last_year'] = df.c_vintage.astype(str)\n",
    "# df.to_pickle('datasets.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also a pull I dont feel like repeating accidentally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# from tqdm import tqdm_notebook\n",
    "# from time import sleep\n",
    "\n",
    "# df = pd.read_pickle('datasets.pkl')\n",
    "# df.c_variablesLink\n",
    "\n",
    "\n",
    "\n",
    "# df2= pd.DataFrame()\n",
    "# def variable_scrape(row):\n",
    "#     title = row['title']\n",
    "#     code = row['code']\n",
    "#     pull = requests.get(row['c_groupsLink'])\n",
    "#     global df2\n",
    "#     if pull.ok:\n",
    "#         backup.append(pull)\n",
    "#         j = pull.json()\n",
    "#         if 'variables' in j:\n",
    "#             new_df = pd.DataFrame(j['variables']).T.reset_index()\n",
    "#             new_df['title'] = title\n",
    "#             new_df['code'] = code\n",
    "#             df2 = df2.append(new_df)\n",
    "#     sleep(1)\n",
    "\n",
    "# for row in tqdm_notebook(df.index):\n",
    "#     variable_scrape(df[['title', 'code', 'c_variablesLink']].loc[row])\n",
    "\n",
    "# df2 = df2.rename({'index':'variable'}, axis=1)\n",
    "# df2 = df2[['code', 'label', 'variable']]\n",
    "\n",
    "# df2.to_pickle('variables.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_pickle('variables.pkl')\n",
    "\n",
    "suffixes = ['PEA', 'PMA', 'PM', 'EA', 'MA', 'PE', 'E', 'M']\n",
    "\n",
    "def strip_all(strip_string):\n",
    "    if not type(strip_string)==str:\n",
    "        return None\n",
    "    for suffix in suffixes:\n",
    "        if strip_string.endswith(suffix):\n",
    "            if '_' in strip_string:\n",
    "                return strip_string.split('_')[0]\n",
    "            else:\n",
    "                return strip_string.strip(suffix)\n",
    "    return strip_string\n",
    "\n",
    "df2['variable_base'] = df2['variable'].apply(strip_all)\n",
    "# df.to_pickle('variable_reference.pkl')\n",
    "\n",
    "\n",
    "variables_by_code = df2.groupby('code').variable_base.unique().to_dict()\n",
    "# variable_labels_by_code = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_pickle('datasets.pkl')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "g = df1.groupby('last_year')\n",
    "# codes_by_year = g.code.agg(lambda x: list(x)).to_dict()\n",
    "titles_by_year = g.title.agg(lambda x: list(x)).to_dict()\n",
    "# descriptions_by_year = g.description.agg(lambda x: list(x)).to_dict()\n",
    "code_by_title = df1[['title', 'code']].set_index('title').to_dict()['code']\n",
    "descriptions_by_title = df1[['title', 'description']].set_index('title').to_dict()['description']\n",
    "\n",
    "vintages = list(df1.c_vintage.astype(str).unique())\n",
    "vintages.sort()\n",
    "vintages.reverse()\n",
    "\n",
    "# df2 = pd.read_pickle('variable_reference.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    vintages,\n",
    "    descriptions_by_title,\n",
    "    code_by_title,\n",
    "    variables_by_code,\n",
    "    titles_by_year\n",
    "]\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open ('data.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)\n",
    "    \n",
    "data_read = pickle.load(open(\"data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
